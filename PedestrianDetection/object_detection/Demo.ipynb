{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 17:06:04.819616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 17:06:04.845718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 17:06:04.845887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 17:06:04.846568: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-21 17:06:04.847160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 17:06:04.847301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 17:06:04.847421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 17:06:05.191346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 17:06:05.191517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 17:06:05.191645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 17:06:05.191753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 923 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from mrcnn import visualize\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "import perception\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = perception.CocoConfig()\n",
    "class_names = ['BG', 'person', 'rider', 'car', 'bus', 'truck', 'bike', 'motor', 'traffic light', 'traffic sign', 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/run/media/sam/Dataset/bdd100k-models/data/bdd100k/images/100k/test/\"\n",
    "coco_dir = \"/home/sam/Desktop/cocoData/\"\n",
    "output_image_path = \"/home/sam/Desktop/output/\"\n",
    "weights_path = \"/home/sam/Documents/GitHub/honoursProject/PedestrianDetection/object_detection/training_log_rgb/coco20190811T1837/mask_rcnn_coco_0005.h5\"\n",
    "MODEL_DIR = \"/home/sam/Documents/GitHub/honoursProject/PedestrianDetection/object_detection/training_log_rgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Re-starting from epoch 5\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "model.load_weights(\n",
    "    weights_path , by_name=True,\n",
    "    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\", \"rpn_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(image_dir):\n",
    "    files= os.listdir(image_dir) \n",
    "    s = []\n",
    "    for file in files: \n",
    "        str_name = file[:21]\n",
    "        s.append(str_name) \n",
    "    return s\n",
    "\n",
    "image_list = get_image_list(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_class_details(class_ids, scores, rois):\n",
    "    \n",
    "    result_array = dict()\n",
    "    for index in range(len(class_ids)):\n",
    "\n",
    "        predicted_class = class_names[class_ids[index]]\n",
    "        predicted_class_score = scores[index].tolist()\n",
    "        predicted_class_boxes = rois[index].tolist()\n",
    "\n",
    "        result_array[predicted_class] = ({\"Confidence\":[predicted_class_score]}, \n",
    "                                                 {\"Bounding box\":[predicted_class_boxes]})\n",
    "\n",
    "    #print(result_array)\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/run/media/sam/Dataset/bdd100k-models/data/bdd100k/images/100k/test/e4206341-c7828824.jpg\n",
      "Processing 1 images\n",
      "image                    shape: (720, 1280, 3)        min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max: -102.90000  float64\n",
      "image_metas              shape: (1, 23)               min:    0.00000  max: 1280.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 17:06:09.828625: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -52 } dim { size: 256 } dim { size: 256 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -19 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -19 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3090\" frequency: 1695 num_cores: 82 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 102400 memory_size: 968687616 bandwidth: 936096000 } outputs { dtype: DT_FLOAT shape { dim { size: -19 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-02-21 17:06:09.828726: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -52 } dim { size: 128 } dim { size: 128 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -22 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -22 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3090\" frequency: 1695 num_cores: 82 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 102400 memory_size: 968687616 bandwidth: 936096000 } outputs { dtype: DT_FLOAT shape { dim { size: -22 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-02-21 17:06:09.828798: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -52 } dim { size: 64 } dim { size: 64 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -24 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3090\" frequency: 1695 num_cores: 82 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 102400 memory_size: 968687616 bandwidth: 936096000 } outputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-02-21 17:06:09.828908: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -52 } dim { size: 32 } dim { size: 32 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -26 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3090\" frequency: 1695 num_cores: 82 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 102400 memory_size: 968687616 bandwidth: 936096000 } outputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-02-21 17:06:09.832967: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -52 } dim { size: 256 } dim { size: 256 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -39 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -39 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3090\" frequency: 1695 num_cores: 82 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 102400 memory_size: 968687616 bandwidth: 936096000 } outputs { dtype: DT_FLOAT shape { dim { size: -39 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-02-21 17:06:09.833055: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -52 } dim { size: 128 } dim { size: 128 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -41 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3090\" frequency: 1695 num_cores: 82 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 102400 memory_size: 968687616 bandwidth: 936096000 } outputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-02-21 17:06:09.833129: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -52 } dim { size: 64 } dim { size: 64 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -43 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -43 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3090\" frequency: 1695 num_cores: 82 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 102400 memory_size: 968687616 bandwidth: 936096000 } outputs { dtype: DT_FLOAT shape { dim { size: -43 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-02-21 17:06:09.833238: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -52 } dim { size: 32 } dim { size: 32 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -45 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -45 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3090\" frequency: 1695 num_cores: 82 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 102400 memory_size: 968687616 bandwidth: 936096000 } outputs { dtype: DT_FLOAT shape { dim { size: -45 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-02-21 17:06:10.863785: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8301\n",
      "2022-02-21 17:06:11.440068: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 413.81M (433913856 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-02-21 17:06:11.440832: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.43M (390522624 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-02-21 17:06:11.441570: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 335.19M (351470592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-02-21 17:06:11.442304: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 301.67M (316323584 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-02-21 17:06:11.443039: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 271.50M (284691456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-02-21 17:06:11.443780: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 244.35M (256222464 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-02-21 17:06:11.444516: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 219.92M (230600448 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-02-21 17:06:11.445259: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 197.93M (207540480 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-02-21 17:06:11.445997: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 178.13M (186786560 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-02-21 17:06:11.446010: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 163.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-02-21 17:06:11.446753: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 413.81M (433913856 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-02-21 17:06:11.446761: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 163.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-02-21 17:06:11.455670: E tensorflow/stream_executor/cuda/cuda_blas.cc:232] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\n",
      "2022-02-21 17:06:11.455851: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : NOT_FOUND: No algorithm worked!  Error messages:\n",
      "  Profiling failure on CUDNN engine 1#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n",
      "  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n",
      "  Profiling failure on CUDNN engine 0#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n",
      "  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n",
      "  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 170917888 bytes.\n",
      "  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 170917888 bytes.\n",
      "  Profiling failure on CUDNN engine 5#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n",
      "  Profiling failure on CUDNN engine 5: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'mask_rcnn/conv1/Conv2D' defined at (most recent call last):\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_10313/4272988316.py\", line 10, in <module>\n      results = model.detect([image], verbose=1)\n    File \"/home/sam/Documents/GitHub/honoursProject/PedestrianDetection/object_detection/mrcnn/model.py\", line 2528, in detect\n      self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'mask_rcnn/conv1/Conv2D'\nDetected at node 'mask_rcnn/conv1/Conv2D' defined at (most recent call last):\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_10313/4272988316.py\", line 10, in <module>\n      results = model.detect([image], verbose=1)\n    File \"/home/sam/Documents/GitHub/honoursProject/PedestrianDetection/object_detection/mrcnn/model.py\", line 2528, in detect\n      self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'mask_rcnn/conv1/Conv2D'\n2 root error(s) found.\n  (0) NOT_FOUND:  No algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 0#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 170917888 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 170917888 bytes.\n  Profiling failure on CUDNN engine 5#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 5: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n\t [[{{node mask_rcnn/conv1/Conv2D}}]]\n\t [[mask_rcnn/mrcnn_detection/ExpandDims_1/_56]]\n  (1) NOT_FOUND:  No algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 0#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 170917888 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 170917888 bytes.\n  Profiling failure on CUDNN engine 5#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 5: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n\t [[{{node mask_rcnn/conv1/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_13024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10313/4272988316.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/honoursProject/PedestrianDetection/object_detection/mrcnn/model.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, images, verbose)\u001b[0m\n\u001b[1;32m   2526\u001b[0m         \u001b[0;31m# Run object detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2527\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrcnn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2528\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmolded_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2529\u001b[0m         \u001b[0;31m# Process detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepL/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'mask_rcnn/conv1/Conv2D' defined at (most recent call last):\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_10313/4272988316.py\", line 10, in <module>\n      results = model.detect([image], verbose=1)\n    File \"/home/sam/Documents/GitHub/honoursProject/PedestrianDetection/object_detection/mrcnn/model.py\", line 2528, in detect\n      self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'mask_rcnn/conv1/Conv2D'\nDetected at node 'mask_rcnn/conv1/Conv2D' defined at (most recent call last):\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_10313/4272988316.py\", line 10, in <module>\n      results = model.detect([image], verbose=1)\n    File \"/home/sam/Documents/GitHub/honoursProject/PedestrianDetection/object_detection/mrcnn/model.py\", line 2528, in detect\n      self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'mask_rcnn/conv1/Conv2D'\n2 root error(s) found.\n  (0) NOT_FOUND:  No algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 0#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 170917888 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 170917888 bytes.\n  Profiling failure on CUDNN engine 5#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 5: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n\t [[{{node mask_rcnn/conv1/Conv2D}}]]\n\t [[mask_rcnn/mrcnn_detection/ExpandDims_1/_56]]\n  (1) NOT_FOUND:  No algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 0#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 170917888 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 170917888 bytes.\n  Profiling failure on CUDNN engine 5#TC: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 5: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4141): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n\t [[{{node mask_rcnn/conv1/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_13024]"
     ]
    }
   ],
   "source": [
    "test_annos = dict()\n",
    "JSON_PATH_OUTPUT = os.path.join(output_image_path, \"results.json\")\n",
    "for i in range(len(image_list)):\n",
    "    image_path = os.path.join(image_dir,image_list[i]) \n",
    "    print(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    results = model.detect([image], verbose=1)\n",
    "\n",
    "\n",
    "    r = results[0]\n",
    "    image_ir = visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                class_names, r['scores'], \n",
    "                                title=\"Predictions\")\n",
    "    plt.savefig(os.path.join(output_image_path,image_list[i]), bbox_inches='tight')\n",
    "     \n",
    "    class_details = get_individual_class_details(r['class_ids'], r['scores'], r['rois'])\n",
    "    test_annos[i] = ({image_list[i] : class_details})\n",
    "    \n",
    "    #test_annos[image_list[i]] = (get_individual_class_details(r['class_ids'], r['scores'], r['rois']))\n",
    "        \n",
    "    if i==2:\n",
    "        break\n",
    "        \n",
    "test_annos = {\"Mask R-CNN with ResNet101 backbone and Feature Pyramid Network (FPN)\": test_annos}\n",
    "#print(test_annos)\n",
    "fd = open(JSON_PATH_OUTPUT, 'w')\n",
    "json.dump(test_annos,fd,indent=4,sort_keys=True)\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
