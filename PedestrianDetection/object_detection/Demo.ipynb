{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 18:43:35.697542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-20 18:43:35.723392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-20 18:43:35.723572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-20 18:43:35.724273: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-20 18:43:35.724901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-20 18:43:35.725045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-20 18:43:35.725165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-20 18:43:36.040699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-20 18:43:36.040866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-20 18:43:36.040994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-20 18:43:36.041101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 840 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from mrcnn import visualize\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "import perception\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = perception.CocoConfig()\n",
    "class_names = ['BG', 'person', 'rider', 'car', 'bus', 'truck', 'bike', 'motor', 'traffic light', 'traffic sign', 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/run/media/sam/Dataset/bdd100k-models/data/bdd100k/images/100k/test/\"\n",
    "coco_dir = \"/home/sam/Desktop/cocoData/\"\n",
    "output_image_path = \"/home/sam/Desktop/output/\"\n",
    "weights_path = \"/home/sam/Desktop/SamHons_ObjectDetection_Repo/object_detection/training_log_rgb/coco20190811T1837/mask_rcnn_coco_0005.h5\"\n",
    "MODEL_DIR = \"/home/sam/Desktop/SamHons_ObjectDetection_Repo/object_detection/training_log_rgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sam/anaconda3/envs/deepL/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer #389 (named \"mrcnn_bbox_fc\"), weight <tf.Variable 'mrcnn_bbox_fc/kernel:0' shape=(1024, 44) dtype=float32, numpy=\narray([[-0.07423402, -0.01301147,  0.03234645, ..., -0.04311334,\n         0.03385313,  0.02864521],\n       [ 0.06854087, -0.03344586,  0.06797224, ...,  0.05952951,\n        -0.00699303,  0.00632061],\n       [-0.05997106,  0.04689942,  0.04211205, ..., -0.04971891,\n         0.05169499,  0.04476684],\n       ...,\n       [-0.06145637, -0.06109542, -0.07162572, ...,  0.0202061 ,\n        -0.03206471, -0.0645671 ],\n       [-0.01481646,  0.06420629,  0.02765223, ..., -0.0666992 ,\n        -0.06287075, -0.00632829],\n       [ 0.02516412,  0.03527036,  0.0312301 , ..., -0.05117411,\n        -0.0243571 ,  0.06873274]], dtype=float32)> has shape (1024, 44), but the saved weight has shape (1024, 324).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10420/4028800646.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/honoursProject/PedestrianDetection/object_detection/mrcnn/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m             \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2136\u001b[0m             \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepL/lib/python3.9/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[0;34m(f, layers, skip_mismatch)\u001b[0m\n\u001b[1;32m    788\u001b[0m                                 weight_values[i].shape))\n\u001b[1;32m    789\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m           raise ValueError('Layer #' + str(k) +' (named \"' + layer.name +\n\u001b[0m\u001b[1;32m    791\u001b[0m                            \u001b[0;34m'\"), weight '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                            ' has shape {}'.format(backend.int_shape(\n",
      "\u001b[0;31mValueError\u001b[0m: Layer #389 (named \"mrcnn_bbox_fc\"), weight <tf.Variable 'mrcnn_bbox_fc/kernel:0' shape=(1024, 44) dtype=float32, numpy=\narray([[-0.07423402, -0.01301147,  0.03234645, ..., -0.04311334,\n         0.03385313,  0.02864521],\n       [ 0.06854087, -0.03344586,  0.06797224, ...,  0.05952951,\n        -0.00699303,  0.00632061],\n       [-0.05997106,  0.04689942,  0.04211205, ..., -0.04971891,\n         0.05169499,  0.04476684],\n       ...,\n       [-0.06145637, -0.06109542, -0.07162572, ...,  0.0202061 ,\n        -0.03206471, -0.0645671 ],\n       [-0.01481646,  0.06420629,  0.02765223, ..., -0.0666992 ,\n        -0.06287075, -0.00632829],\n       [ 0.02516412,  0.03527036,  0.0312301 , ..., -0.05117411,\n        -0.0243571 ,  0.06873274]], dtype=float32)> has shape (1024, 44), but the saved weight has shape (1024, 324)."
     ]
    }
   ],
   "source": [
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(image_dir):\n",
    "    files= os.listdir(image_dir) \n",
    "    s = []\n",
    "    for file in files: \n",
    "        str_name = file[:21]\n",
    "        s.append(str_name) \n",
    "    return s\n",
    "\n",
    "image_list = get_image_list(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_class_details(class_ids, scores, rois):\n",
    "    \n",
    "    result_array = dict()\n",
    "    for index in range(len(class_ids)):\n",
    "\n",
    "        predicted_class = class_names[class_ids[index]]\n",
    "        predicted_class_score = scores[index].tolist()\n",
    "        predicted_class_boxes = rois[index].tolist()\n",
    "\n",
    "        result_array[predicted_class] = ({\"Confidence\":[predicted_class_score]}, \n",
    "                                                 {\"Bounding box\":[predicted_class_boxes]})\n",
    "\n",
    "    #print(result_array)\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_annos = dict()\n",
    "JSON_PATH_OUTPUT = os.path.join(output_image_path, \"results.json\")\n",
    "for i in range(len(image_list)):\n",
    "    image_path = os.path.join(image_dir,image_list[i]) \n",
    "    print(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    results = model.detect([image], verbose=1)\n",
    "\n",
    "\n",
    "    r = results[0]\n",
    "    image_ir = visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                class_names, r['scores'], \n",
    "                                title=\"Predictions\")\n",
    "    plt.savefig(os.path.join(output_image_path,image_list[i]), bbox_inches='tight')\n",
    "     \n",
    "    class_details = get_individual_class_details(r['class_ids'], r['scores'], r['rois'])\n",
    "    test_annos[i] = ({image_list[i] : class_details})\n",
    "    \n",
    "    #test_annos[image_list[i]] = (get_individual_class_details(r['class_ids'], r['scores'], r['rois']))\n",
    "        \n",
    "    if i==2:\n",
    "        break\n",
    "        \n",
    "test_annos = {\"Mask R-CNN with ResNet101 backbone and Feature Pyramid Network (FPN)\": test_annos}\n",
    "#print(test_annos)\n",
    "fd = open(JSON_PATH_OUTPUT, 'w')\n",
    "json.dump(test_annos,fd,indent=4,sort_keys=True)\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
