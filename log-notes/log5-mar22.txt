3rd

Going to create pedestrian detection notebook

Will look to alter so it used DTilaks Perception file as its related to BDD directly

_________________________

6th

Still cant get CV to loop through folder of videos but it works well when passed the video path

Moving on to configuring toi work with perception.py from Dtalik and the BSS labels

Will then look to select individual frames of a video with a pedestrian walking and look too identify and log coordinates


__________________________________________________

7th

Writing script to break video into frames and save to a location

______________________________________________________________

8th 

Trying to feed each frame into model to view and log output of bounding boxes.


______________________________________________________________

10th

Still cant get opon cv to read frames seperatley and run model 

meeting with mark where I will bring this up

Have found image processing DTilaks work so will reference 

https://github.com/TilakD/Object-detection-and-segmentation-for-self-driving-cars/blob/master/object_detection/inspect_model.ipynb

https://github.com/TilakD/Object-detection-and-segmentation-for-self-driving-cars/blob/master/object_detection/Demo.ipynb

to find a solution to reading images and procesing the bounding boxes

________________________________________________________________


11th

Got frames reading speratley and in order

Object detection considers each frame new so no tracking is applied

Will look into this

________________________________________________________________

14th

Spoke to Mark and he states creating a tracking program to track multiple object through busy frames is above this stage in education

Aims are to remove all labels bar pedestrians

2 frames at a time log pedestrians and coordinates 

    Most of the time a pedestrian will be the same in the next frame if the coordinate has moved fractionally

    This would not be the case when a large group of people are walking enar each other

Create dataset from pedestrian movement

logging coordinates and pedestrian

do distance calculation between points 1 and 2

Then look to get agorithm that can predicts 6-10 frames into the future

**For discussion 
    state final programe would need to track targets independantly but until a real system is being implemented this is not possible

______________________________________________________________

15th

- Remove unecessary labels (if possible)

using this stack overlfow to try and reduce classes and class id's
https://stackoverflow.com/questions/65810714/mask-rcnn-1-class-only

Error seems to be hit which I think is versioning but will investigate further tomorrow


__________________________________________________________________

18th

Removing all labels classes bar person and retrianing model continues

had to update model from this repo: https://github.com/leekunhee/Mask_RCNN

running training and its taking forever to get by 1 epoch currentl 25 mins

asked mark if anyway to speed this up or approach the training differently

Ran trianing for over 2 hours and still no movement from epoch 1. 

Looked up to see if any solutions but none so far. Will continue this on next session


_____________________________________________________

19th

Ran model overnight and no progress from epoch 1 after 700 mins

spoke to Tony and he has suggested adding in a set workers number and verbose= 1 to see progress

in model.py around lin 2364, workers=8 instead of workers=workers was added. verbose 1 was added and multiprocessing set to True instead of = workers > 1

commented out the if statements to check if system is running on windows

now looking to add a model.summary to see if it hangs before trianing starts

added print line in model aroun 2364 and stats show 

Total params: 65,828,510
Trainable params: 21,069,086
Non-trainable params: 44,759,424


Changed model lines back to original

added print line to find out how many workers were being used
16 if not set

I have set this to 1 to see if anything changes 


________________________________________________

20th 

After speaking to Mark I will no longer try to retrain the model 

I will look to extract the results data and log pedestraiand and their x1 y2 coordinates

plan for tomorrow:

    reduce to just 1 frame till you can isolate the info you need
    look to identify rois and object label
    Store only pedestrian data
    run frame 2 and try to identify the same people from very slight movements
    build script to do this for video 2 frames at a time and build dataset

_____________________________________________________________

21st

Message from Mark confirms the plan is best route forward

No need to retrain and instead will get data extracted from results

plan for today:

    reduce to just 1 frame till you can isolate the info you need
    look to identify rois and object label
    Store only pedestrian data
    run frame 2 and try to identify the same people from very slight movements
    build script to do this for video 2 frames at a time and build dataset


Got 1 frame reading
Managed to extract data for each object in frame
looking to create a dictionary with this data

once create will remove everything bar person class

look to log people to identify in next frame

Once one can be done will look to have a frame dictionay holding the frame data dictionaries

__________________________________________________________________

22nd

Following on from yesterday I will try and create a dictionary of objects within frame and there locations

Once done I will remove all bar person data

I will complete this for frame 2 and look to see if probability can determin 
if a person is the same as the frame before due to minimal movement

if this can be done then I will write a script to perform this for a whole video
Then aim to write a script to extract from 2 videos into the same collection

Managed to get info adding to dictionary on a per object basis
Removed all objects bar person and logged the number ie person 1 person 2
Trying to get each coordinate out of the rois array to compare but cant do this yesterday

Tomorrow:

Get each coordinate out for each person ROIS in frame 1 and 2
Write script to compare and link the same person via similar coordinates
Any new coordinates will be taken as a new person
Get infor for frames logged in the fashion of 
frame 1 Person 1 position
frame 2 person 1 position

___________________________________________________________________-

23rd

Continuing on from yesterday I will be trying to extract the elements within ROIS array

Completed today:

Got ROIS coordinates extracting seperatley and being added to object dictionary for person
Created script for breaking video into frames so code does not repeat
Selected better videos to take data from

Tomorrow:

Create loop of 2 frames
    Create loop of objects i frame
        add person to objects collection
    add object to frames collection

potentially count people in frame and total across all frames. ie 1 person across 2 frames should equal 2 people only

Should have frames dictonary containing 2 frames and each frame should have a person object in it

Once this is done will work on calculation and person labelling

Then will build script to run for full video

If possible will do the same for the 4 videos


